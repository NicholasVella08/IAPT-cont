{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695395d1",
   "metadata": {},
   "source": [
    "# With My Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a509c1",
   "metadata": {},
   "source": [
    "## Fine-Tuning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8802dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputText):\n",
    "    #dividing in the Triples into 3 strings (Subject, Predicate and Object)\n",
    "    strings = input_string.split(' | ')\n",
    "    string1 = strings[0]\n",
    "    string2 = strings[1]\n",
    "    string3 = strings[2]\n",
    "    \n",
    "    # Removing unwanted symbols\n",
    "    if '_' in string1:\n",
    "        string1 = string1.replace('_', ' ')\n",
    "\n",
    "    if '_' in string2:\n",
    "        string2 = string2.replace('_', ' ')\n",
    "                \n",
    "    if '_' in string3:\n",
    "        string3 = string3.replace('_', ' ')\n",
    "\n",
    "    if '\"' in string3:\n",
    "        string3 = string3.replace('\"', '')\n",
    "        \n",
    "    \n",
    "    #Modified Triple\n",
    "    MR = \"__subject__ \" + string1 + \" __predicate__ \" + string2 + \" __object__ \" + string3\n",
    "    \n",
    "    return MR, string1, string2, string3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f8f74",
   "metadata": {},
   "source": [
    "## Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25def9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from benchmark_reader import Benchmark\n",
    "from benchmark_reader import select_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# using benchmark_reader.py for extracting data from the dataset\n",
    "b = Benchmark()\n",
    "files = select_files('en/train')\n",
    "b.fill_benchmark(files)\n",
    "\n",
    "RDF1_triples_texts, RDF1_predicate_train, RDF1_subject_train, RDF1_object_train = [], [], [], []\n",
    "RDF2_triples_texts, RDF2_predicate_train, RDF2_subject_train, RDF2_object_train = [], [], [], []\n",
    "RDF3_triples_texts, RDF3_predicate_train, RDF3_subject_train, RDF3_object_train = [], [], [], []\n",
    "RDF4_triples_texts, RDF4_predicate_train, RDF4_subject_train, RDF4_object_train = [], [], [], []\n",
    "RDF5_triples_texts, RDF5_predicate_train, RDF5_subject_train, RDF5_object_train = [], [], [], []\n",
    "RDF6_triples_texts, RDF6_predicate_train, RDF6_subject_train, RDF6_object_train = [], [], [], []\n",
    "RDF7_triples_texts, RDF7_predicate_train, RDF7_subject_train, RDF7_object_train = [], [], [], []\n",
    "\n",
    "max_triples = 0\n",
    "for i in range(b.entry_count()):\n",
    "    entry = b.entries[i]\n",
    "    \n",
    "    length = entry.size\n",
    "    # for 1RDF\n",
    "    if length == '1':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        #For each text\n",
    "        for lex in range(len(texts)):\n",
    "            RDF1_triple = []\n",
    "            text = []\n",
    "            # For each RDF\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF1_triple.append(MR)\n",
    "                RDF1_subject_train.append(string1)\n",
    "                RDF1_predicate_train.append(string2)\n",
    "                RDF1_object_train.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "\n",
    "        \n",
    "            RDF1_triples_texts.append((RDF1_triple, texts[lex].lex))\n",
    "    #For 2RDF        \n",
    "    if length == '2':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF2_triple = []\n",
    "            text = []\n",
    "            RDF2_sub = []\n",
    "            RDF2_obj =[]\n",
    "            RDF2_pre =[]\n",
    "            RDF2_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF2_MR.append(MR)\n",
    "                RDF2_sub.append(string1)\n",
    "                RDF2_pre.append(string2)\n",
    "                RDF2_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF2_triple.append(RDF2_MR)\n",
    "            RDF2_subject_train.append(RDF2_sub)\n",
    "            RDF2_predicate_train.append(RDF2_pre)\n",
    "            RDF2_object_train.append(RDF2_obj)\n",
    "        \n",
    "            RDF2_triples_texts.append((RDF2_triple, texts[lex].lex))       \n",
    "    #For 3RDF        \n",
    "    if length == '3':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF3_triple = []\n",
    "            text = []\n",
    "            RDF3_sub = []\n",
    "            RDF3_obj =[]\n",
    "            RDF3_pre =[]\n",
    "            RDF3_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF3_MR.append(MR)\n",
    "                RDF3_sub.append(string1)\n",
    "                RDF3_pre.append(string2)\n",
    "                RDF3_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF3_triple.append(RDF3_MR)\n",
    "            RDF3_subject_train.append(RDF3_sub)\n",
    "            RDF3_predicate_train.append(RDF3_pre)\n",
    "            RDF3_object_train.append(RDF3_obj)\n",
    "        \n",
    "            RDF3_triples_texts.append((RDF3_triple, texts[lex].lex))  \n",
    "    #For 4RDF        \n",
    "    if length == '4':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF4_triple = []\n",
    "            text = []\n",
    "            RDF4_sub = []\n",
    "            RDF4_obj =[]\n",
    "            RDF4_pre =[]\n",
    "            RDF4_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF4_MR.append(MR)\n",
    "                RDF4_sub.append(string1)\n",
    "                RDF4_pre.append(string2)\n",
    "                RDF4_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF4_triple.append(RDF4_MR)\n",
    "            RDF4_subject_train.append(RDF4_sub)\n",
    "            RDF4_predicate_train.append(RDF4_pre)\n",
    "            RDF4_object_train.append(RDF4_obj)\n",
    "        \n",
    "            RDF4_triples_texts.append((RDF4_triple, texts[lex].lex))     \n",
    "    # For 5 RDF        \n",
    "    if length == '5':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF5_triple = []\n",
    "            text = []\n",
    "            RDF5_sub = []\n",
    "            RDF5_obj =[]\n",
    "            RDF5_pre =[]\n",
    "            RDF5_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF5_MR.append(MR)\n",
    "                RDF5_sub.append(string1)\n",
    "                RDF5_pre.append(string2)\n",
    "                RDF5_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF5_triple.append(RDF5_MR)\n",
    "            RDF5_subject_train.append(RDF5_sub)\n",
    "            RDF5_predicate_train.append(RDF5_pre)\n",
    "            RDF5_object_train.append(RDF5_obj)\n",
    "        \n",
    "            RDF5_triples_texts.append((RDF5_triple, texts[lex].lex)) \n",
    "    # For 6 RDF        \n",
    "    if length == '6':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF6_triple = []\n",
    "            text = []\n",
    "            RDF6_sub = []\n",
    "            RDF6_obj =[]\n",
    "            RDF6_pre =[]\n",
    "            RDF6_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF6_MR.append(MR)\n",
    "                RDF6_sub.append(string1)\n",
    "                RDF6_pre.append(string2)\n",
    "                RDF6_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF6_triple.append(RDF6_MR)\n",
    "            RDF6_subject_train.append(RDF6_sub)\n",
    "            RDF6_predicate_train.append(RDF6_pre)\n",
    "            RDF6_object_train.append(RDF6_obj)\n",
    "        \n",
    "            RDF6_triples_texts.append((RDF6_triple, texts[lex].lex))  \n",
    "    #For 7 RDF \n",
    "    if length == '7':\n",
    "        category = entry.category\n",
    "        data = entry.list_triples()\n",
    "        texts = entry.lexs\n",
    "        \n",
    "        for lex in range(len(texts)):\n",
    "            RDF7_triple = []\n",
    "            text = []\n",
    "            RDF7_sub = []\n",
    "            RDF7_obj =[]\n",
    "            RDF7_pre =[]\n",
    "            RDF7_MR = []\n",
    "            for RDF in range(len(entry.list_triples())):\n",
    "                input_string = data[RDF]\n",
    "\n",
    "                MR, string1, string2, string3 = preprocess(input_string)\n",
    "                \n",
    "                RDF7_MR.append(MR)\n",
    "                RDF7_sub.append(string1)\n",
    "                RDF7_pre.append(string2)\n",
    "                RDF7_obj.append(string3)\n",
    "                max_triples= max_triples+1\n",
    "            RDF7_triple.append(RDF7_MR)\n",
    "            RDF7_subject_train.append(RDF7_sub)\n",
    "            RDF7_predicate_train.append(RDF7_pre)\n",
    "            RDF7_object_train.append(RDF7_obj)\n",
    "        \n",
    "            RDF7_triples_texts.append((RDF7_triple, texts[lex].lex))  \n",
    "\n",
    "            \n",
    "            \n",
    "RDF1_train_data = RDF1_triples_texts\n",
    "RDF2_train_data = RDF2_triples_texts\n",
    "RDF3_train_data = RDF3_triples_texts\n",
    "RDF4_train_data = RDF4_triples_texts\n",
    "RDF5_train_data = RDF5_triples_texts\n",
    "RDF6_train_data = RDF6_triples_texts\n",
    "RDF7_train_data = RDF7_triples_texts\n",
    "\n",
    "\n",
    "        \n",
    "# Saving Output to .txt files\n",
    "with open('RDF 1/RDF1.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF1_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + RDF1_subject_train[i] + \"\\n\")\n",
    "        f.write(\"Predicate: \" + RDF1_predicate_train[i] + \"\\n\")\n",
    "        f.write(\"Object: \" + RDF1_object_train[i] + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 2/RDF2.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF2_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF2_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF2_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF2_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 3/RDF3.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF3_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF3_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF3_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF3_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 4/RDF4.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF4_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF4_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF4_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF4_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 5/RDF5.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF5_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF5_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF5_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF5_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 6/RDF6.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF6_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF6_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF6_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF6_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 7/RDF7.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    for triple, text in RDF7_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\")\n",
    "        f.write(\"Text: \" + str(text) + \"\\n\")\n",
    "        f.write(\"Subject: \" + str(RDF7_subject_train[i]) + \"\\n\")\n",
    "        f.write(\"Predicate: \" + str(RDF7_predicate_train[i]) + \"\\n\")\n",
    "        f.write(\"Object: \" + str(RDF7_object_train[i]) + \"\\n\\n\")\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3625432",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99309b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the XML file\n",
    "tree = ET.parse('en/test/rdf-to-text-generation-test-data-without-refs-en.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "mtriples = []\n",
    "RDF1_test_triples_texts, RDF1_subject_test, RDF1_predicate_test, RDF1_object_test = [], [], [], []\n",
    "RDF2_test_triples_texts, RDF2_subject_test, RDF2_predicate_test, RDF2_object_test = [], [], [], []\n",
    "RDF3_test_triples_texts, RDF3_subject_test, RDF3_predicate_test, RDF3_object_test = [], [], [], []\n",
    "RDF4_test_triples_texts, RDF4_subject_test, RDF4_predicate_test, RDF4_object_test = [], [], [], []\n",
    "RDF5_test_triples_texts, RDF5_subject_test, RDF5_predicate_test, RDF5_object_test = [], [], [], []\n",
    "RDF6_test_triples_texts, RDF6_subject_test, RDF6_predicate_test, RDF6_object_test = [], [], [], []\n",
    "RDF7_test_triples_texts, RDF7_subject_test, RDF7_predicate_test, RDF7_object_test = [], [], [], []\n",
    "\n",
    "\n",
    "# Iterate over each 'entry' element\n",
    "for entry in root.findall('.//entry'):\n",
    "    \n",
    "    \n",
    "    # Iterate over each 'mtriple' element within 'modifiedtripleset'\n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 1:\n",
    "        RDF1_triple = []\n",
    "        \n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            RDF1_subject_test.append(string1)\n",
    "            RDF1_predicate_test.append(string2)\n",
    "            RDF1_object_test.append(string3)\n",
    "            RDF1_triple.append(MR)\n",
    "            #mtriples.append(triple)\n",
    "        \n",
    "        RDF1_test_triples_texts.append(RDF1_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 2:\n",
    "        RDF2_triple = []\n",
    "        TRDF2_sub = []\n",
    "        TRDF2_obj =[]\n",
    "        TRDF2_pre =[]\n",
    "        TRDF2_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF2_MR.append(MR)\n",
    "            TRDF2_sub.append(string1)\n",
    "            TRDF2_pre.append(string2)\n",
    "            TRDF2_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF2_triple.append(TRDF2_MR)\n",
    "        RDF2_subject_test.append(TRDF2_sub)\n",
    "        RDF2_predicate_test.append(TRDF2_pre)\n",
    "        RDF2_object_test.append(TRDF2_obj)\n",
    "            \n",
    "        RDF2_test_triples_texts.append(RDF2_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 3:\n",
    "        RDF3_triple = []\n",
    "        TRDF3_sub = []\n",
    "        TRDF3_obj =[]\n",
    "        TRDF3_pre =[]\n",
    "        TRDF3_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF3_MR.append(MR)\n",
    "            TRDF3_sub.append(string1)\n",
    "            TRDF3_pre.append(string2)\n",
    "            TRDF3_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF3_triple.append(TRDF3_MR)\n",
    "        RDF3_subject_test.append(TRDF3_sub)\n",
    "        RDF3_predicate_test.append(TRDF3_pre)\n",
    "        RDF3_object_test.append(TRDF3_obj)\n",
    "            \n",
    "        RDF3_test_triples_texts.append(RDF3_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 4:\n",
    "        RDF4_triple = []\n",
    "        TRDF4_sub = []\n",
    "        TRDF4_obj =[]\n",
    "        TRDF4_pre =[]\n",
    "        TRDF4_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF4_MR.append(MR)\n",
    "            TRDF4_sub.append(string1)\n",
    "            TRDF4_pre.append(string2)\n",
    "            TRDF4_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF4_triple.append(TRDF4_MR)\n",
    "        RDF4_subject_test.append(TRDF4_sub)\n",
    "        RDF4_predicate_test.append(TRDF4_pre)\n",
    "        RDF4_object_test.append(TRDF4_obj)\n",
    "            \n",
    "        RDF4_test_triples_texts.append(RDF4_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 5:\n",
    "        RDF5_triple = []\n",
    "        TRDF5_sub = []\n",
    "        TRDF5_obj =[]\n",
    "        TRDF5_pre =[]\n",
    "        TRDF5_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF5_MR.append(MR)\n",
    "            TRDF5_sub.append(string1)\n",
    "            TRDF5_pre.append(string2)\n",
    "            TRDF5_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF5_triple.append(TRDF5_MR)\n",
    "        RDF5_subject_test.append(TRDF5_sub)\n",
    "        RDF5_predicate_test.append(TRDF5_pre)\n",
    "        RDF5_object_test.append(TRDF5_obj)\n",
    "            \n",
    "        RDF5_test_triples_texts.append(RDF5_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 6:\n",
    "        RDF6_triple = []\n",
    "        TRDF6_sub = []\n",
    "        TRDF6_obj =[]\n",
    "        TRDF6_pre =[]\n",
    "        TRDF6_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF6_MR.append(MR)\n",
    "            TRDF6_sub.append(string1)\n",
    "            TRDF6_pre.append(string2)\n",
    "            TRDF6_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF6_triple.append(TRDF6_MR)\n",
    "        RDF6_subject_test.append(TRDF6_sub)\n",
    "        RDF6_predicate_test.append(TRDF6_pre)\n",
    "        RDF6_object_test.append(TRDF6_obj)\n",
    "            \n",
    "        RDF6_test_triples_texts.append(RDF6_triple)\n",
    "        \n",
    "    if len(entry.findall('.//modifiedtripleset/mtriple')) == 7:\n",
    "        RDF7_triple = []\n",
    "        TRDF7_sub = []\n",
    "        TRDF7_obj =[]\n",
    "        TRDF7_pre =[]\n",
    "        TRDF7_MR = []\n",
    "        for mtriple in entry.findall('.//modifiedtripleset/mtriple'):\n",
    "            input_string = mtriple.text\n",
    "\n",
    "            MR, string1, string2, string3 = preprocess(input_string)\n",
    "            \n",
    "            TRDF7_MR.append(MR)\n",
    "            TRDF7_sub.append(string1)\n",
    "            TRDF7_pre.append(string2)\n",
    "            TRDF7_obj.append(string3)\n",
    "            max_triples= max_triples+1\n",
    "        RDF7_triple.append(TRDF7_MR)\n",
    "        RDF7_subject_test.append(TRDF7_sub)\n",
    "        RDF7_predicate_test.append(TRDF7_pre)\n",
    "        RDF7_object_test.append(TRDF7_obj)\n",
    "            \n",
    "        RDF7_test_triples_texts.append(RDF7_triple)\n",
    "        \n",
    "#Saving the output in .txt files        \n",
    "        \n",
    "with open('RDF 1/RDF1_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF1_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ RDF1_subject_test[i]+\"\\n\" + \"predicate: \"+ RDF1_predicate_test[i]+\"\\n\"+ \"object: \"+ RDF1_object_test[i]+\"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 2/RDF2_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF2_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF2_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF2_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF2_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 3/RDF3_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF3_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF3_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF3_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF3_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 4/RDF4_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF4_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF4_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF4_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF4_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 5/RDF5_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF5_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF5_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF5_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF5_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1\n",
    "        \n",
    "with open('RDF 6/RDF6_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF6_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF6_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF6_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF6_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1\n",
    "\n",
    "with open('RDF 7/RDF7_Test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    i=0\n",
    "    for triple in RDF7_test_triples_texts:\n",
    "        f.write(\"Triple: \" + str(triple) + \"\\n\" + \"subject: \"+ str(RDF7_subject_test[i])+\"\\n\" + \"predicate: \"+ str(RDF7_predicate_test[i])+\"\\n\"+ \"object: \"+ str(RDF7_object_test[i])+\"\\n\\n\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f3da4",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938b2c5",
   "metadata": {},
   "source": [
    "###  1 Triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95b6b1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "deathDate\n",
      "populationDensity\n",
      "birthDate\n",
      "areaCode\n",
      "officialLanguage\n",
      "location\n",
      "influencedBy\n",
      "spouse\n",
      "utcOffset\n",
      "areaTotal\n",
      "location\n",
      "professionalField\n",
      "musicComposer\n",
      "starring\n",
      "director\n",
      "genre\n",
      "followedBy\n",
      "timeZone\n",
      "nationality\n",
      "professionalField\n",
      "birthPlace\n",
      "producer\n",
      "musicSubgenre\n",
      "leaderTitle\n",
      "postalCode\n",
      "demonym\n",
      "literaryGenre\n",
      "populationDensity\n",
      "runwayName\n",
      "governmentType\n",
      "leader\n",
      "genre\n",
      "recordLabel\n",
      "stylisticOrigin\n",
      "producer\n",
      "birthYear\n",
      "cityServed\n",
      "genre\n",
      "writer\n",
      "sisterStation\n",
      "deathDate\n",
      "keyPerson\n",
      "award\n",
      "leader\n",
      "broadcastedBy\n",
      "genre\n",
      "instrument\n",
      "officialLanguage\n",
      "deathYear\n",
      "parentCompany\n",
      "writer\n",
      "followedBy\n",
      "leader\n",
      "citizenship\n",
      "numberOfUndergraduateStudents\n",
      "numberOfStudents\n",
      "recordLabel\n",
      "currency\n",
      "timeshiftChannel\n",
      "deathYear\n",
      "notableWork\n",
      "type\n",
      "leaderTitle\n",
      "apoapsis\n",
      "associatedBand/associatedMusicalArtist\n",
      "stylisticOrigin\n",
      "nationality\n",
      "birthDate\n",
      "foundingYear\n",
      "instrument\n",
      "genre\n",
      "isPartOf\n",
      "followedBy\n",
      "birthDate\n",
      "residence\n",
      "cinematography\n",
      "followedBy\n",
      "currency\n",
      "recordLabel\n",
      "leaderTitle\n",
      "professionalField\n",
      "demonym\n",
      "releaseDate\n",
      "professionalField\n",
      "birthDate\n",
      "owner\n",
      "knownFor\n",
      "leader\n",
      "genre\n",
      "language\n",
      "isPartOf\n",
      "professionalField\n",
      "populationTotal\n",
      "imdbId\n",
      "leader\n",
      "isPartOf\n",
      "producer\n",
      "formerName\n",
      "timeZone\n",
      "literaryGenre\n",
      "isPartOf\n",
      "deathPlace\n",
      "musicalBand\n",
      "genre\n",
      "spouse\n",
      "timeZone\n",
      "imdbId\n",
      "leader\n",
      "areaCode\n",
      "distributor\n",
      "birthPlace\n",
      "musicSubgenre\n",
      "successor\n",
      "foundingYear\n",
      "demonym\n",
      "populationMetro\n",
      "genre\n",
      "precededBy\n",
      "staff\n",
      "director\n",
      "region\n",
      "religion\n",
      "artist\n",
      "birthYear\n",
      "cinematography\n",
      "musicalArtist\n",
      "leaderTitle\n",
      "activeYearsStartYear\n",
      "leaderTitle\n",
      "utcOffset\n",
      "birthPlace\n",
      "citizenship\n",
      "areaTotal\n",
      "governmentType\n",
      "birthName\n",
      "keyPerson\n",
      "utcOffset\n",
      "weight\n",
      "percentageOfAreaWater\n",
      "utcOffset\n",
      "distributingLabel\n",
      "writer\n",
      "editing\n",
      "birthPlace\n",
      "populationTotal\n",
      "isPartOf\n",
      "country\n",
      "producer\n",
      "birthPlace\n",
      "precededBy\n",
      "deathPlace\n",
      "discoverer\n",
      "starring\n",
      "followedBy\n",
      "birthDate\n",
      "instrument\n",
      "longName\n",
      "birthDate\n",
      "areaTotal\n",
      "musicSubgenre\n",
      "assembly\n",
      "country\n",
      "city\n",
      "recordLabel\n",
      "birthDate\n",
      "format\n",
      "writer\n",
      "album\n",
      "producer\n",
      "leader\n",
      "product\n",
      "musicSubgenre\n",
      "genre\n",
      "genre\n",
      "distributor\n",
      "operatingOrganisation\n",
      "producer\n",
      "birthPlace\n",
      "genre\n",
      "leaderTitle\n",
      "elevationAboveTheSeaLevel\n",
      "stylisticOrigin\n",
      "discovered\n",
      "starring\n",
      "parentCompany\n",
      "runtime\n",
      "isPartOf\n",
      "country\n",
      "activeYearsStartYear\n",
      "musicFusionGenre\n",
      "followedBy\n",
      "ethnicGroup\n",
      "derivative\n",
      "deathPlace\n",
      "numberOfEmployees\n",
      "derivative\n",
      "writer\n",
      "activeYearsStartYear\n",
      "country\n",
      "followedBy\n",
      "professionalField\n",
      "precededBy\n",
      "isPartOf\n",
      "city\n",
      "elevationAboveTheSeaLevel\n",
      "precededBy\n",
      "recordedIn\n",
      "runwayLength\n",
      "releaseDate\n",
      "recordLabel\n",
      "genre\n",
      "isPartOf\n",
      "leaderTitle\n",
      "foundingDate\n",
      "numberOfPostgraduateStudents\n",
      "nationality\n",
      "birthPlace\n",
      "foundingDate\n",
      "runtime\n",
      "operatingIncome\n",
      "knownFor\n",
      "certification\n",
      "formerBandMember\n",
      "writer\n",
      "leaderTitle\n",
      "birthDate\n",
      "icaoLocationIdentifier\n",
      "leaderTitle\n",
      "releaseDate\n",
      "publisher\n",
      "runtime\n",
      "spouse\n",
      "almaMater\n",
      "album\n",
      "knownFor\n",
      "service\n",
      "extinctionDate\n",
      "musicFusionGenre\n",
      "runtime\n",
      "leader\n",
      "campus\n",
      "gridReference\n",
      "followedBy\n",
      "knownFor\n",
      "areaTotal\n",
      "background\n",
      "precededBy\n",
      "runwaySurfaceType\n",
      "location\n",
      "leader\n",
      "producer\n",
      "longName\n",
      "location\n",
      "longName\n",
      "writer\n",
      "editor\n",
      "runtime\n",
      "musicFusionGenre\n",
      "birthDate\n",
      "periapsis\n",
      "elevationAboveTheSeaLevel\n",
      "postalCode\n",
      "gross\n",
      "language\n",
      "musicComposer\n",
      "recordedIn\n",
      "industry\n",
      "associatedBand/associatedMusicalArtist\n",
      "child\n",
      "producer\n",
      "stylisticOrigin\n",
      "manufacturer\n",
      "ceremonialCounty\n",
      "birthDate\n",
      "service\n",
      "genre\n",
      "precededBy\n",
      "professionalField\n",
      "type\n",
      "motto\n",
      "birthDate\n",
      "keyPerson\n",
      "director\n",
      "areaCode\n",
      "meaning\n",
      "followedBy\n",
      "precededBy\n",
      "country\n",
      "keyPerson\n",
      "deathPlace\n",
      "timeZone\n",
      "followedBy\n",
      "recordLabel\n",
      "almaMater\n",
      "runtime\n",
      "starring\n",
      "leaderTitle\n",
      "bodyStyle\n",
      "elevationAboveTheSeaLevel\n",
      "cosparId\n",
      "timeZone\n",
      "parentCompany\n",
      "releaseDate\n",
      "longName\n",
      "utcOffset\n",
      "foundingYear\n",
      "activeYearsStartYear\n",
      "spouse\n",
      "deathDate\n",
      "birthPlace\n",
      "leaderTitle\n",
      "chancellor\n",
      "author\n",
      "residence\n",
      "numberOfDoctoralStudents\n",
      "occupation\n",
      "birthPlace\n",
      "birthPlace\n",
      "areaTotal\n",
      "nationality\n",
      "areaTotal\n",
      "starring\n",
      "populationMetroDensity\n",
      "product\n",
      "knownFor\n",
      "leaderTitle\n",
      "director\n",
      "releaseDate\n",
      "occupation\n",
      "producer\n",
      "knownFor\n",
      "producer\n",
      "areaTotal\n",
      "birthDate\n",
      "director\n",
      "leaderTitle\n",
      "areaOfWater\n",
      "productionEndYear\n",
      "occupation\n",
      "publisher\n",
      "deathPlace\n",
      "residence\n",
      "child\n",
      "deathDate\n",
      "officialLanguage\n",
      "iso6392Code\n",
      "numberOfEmployees\n",
      "formerBandMember\n",
      "assembly\n",
      "foundingDate\n",
      "height\n",
      "populationTotal\n",
      "birthDate\n",
      "precededBy\n",
      "birthPlace\n",
      "followedBy\n",
      "associatedBand/associatedMusicalArtist\n",
      "literaryGenre\n",
      "orbitalPeriod\n",
      "isPartOf\n",
      "deathDate\n",
      "areaTotal\n",
      "type\n",
      "absoluteMagnitude\n",
      "leaderTitle\n",
      "starring\n",
      "writer\n",
      "birthPlace\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def oneRDF(test_sub, test_pred,test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF1_predicate_train)):\n",
    "        if test_pred == RDF1_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF1_train_data[i][0])\n",
    "            train_matching_text.append(RDF1_train_data[i][1])\n",
    "            #print(RDF1_train_data[i][1])\n",
    "                \n",
    "    for x in train_matching_index:           \n",
    "        if RDF1_subject_train[x] in str(RDF1_train_data[x][1]) and RDF1_object_train[x] in str(RDF1_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF1_train_data[x][1]).replace(RDF1_subject_train[x], test_sub).replace(RDF1_object_train[x], test_obj)\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "            \n",
    "    references = [RDF1_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    else:\n",
    "        # If no matches found\n",
    "        return None, None\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "with open('RDF 1/RDF1_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF1_predicate_test)):\n",
    "        print(str(RDF1_predicate_test[x]))\n",
    "        original, generated = oneRDF(RDF1_subject_test[x], RDF1_predicate_test[x], RDF1_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "\n",
    "#oneRDF(RDF1_predicate_test[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d7825",
   "metadata": {},
   "source": [
    "### 2 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d8230cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birthDate', 'occupation']\n",
      "['precededBy', 'followedBy']\n",
      "['foundingDate', 'product']\n",
      "['publisher', 'literaryGenre']\n",
      "['location', 'industry']\n",
      "['residence', 'party']\n",
      "['starring', 'writer']\n",
      "['periapsis', 'epoch']\n",
      "['timeZone', 'populationDensity']\n",
      "['numberOfEmployees', 'netIncome']\n",
      "['followedBy', 'artist']\n",
      "['utcOffset', 'isPartOf']\n",
      "['artist', 'associatedBand/associatedMusicalArtist']\n",
      "['buildDate', 'builder']\n",
      "['nationality', 'ethnicGroup']\n",
      "['completionDate', 'owner']\n",
      "['isPartOf', 'leader']\n",
      "['country', 'leader']\n",
      "['professionalField', 'almaMater']\n",
      "['genre', 'associatedBand/associatedMusicalArtist']\n",
      "['nativeName', 'location']\n",
      "['starring', 'gross']\n",
      "['creator', 'broadcastedBy']\n",
      "['starring', 'cinematography']\n",
      "['foundingDate', 'type']\n",
      "['birthYear', 'debutTeam']\n",
      "['deathPlace', 'areaTotal']\n",
      "['location', 'operatingOrganisation']\n",
      "['assembly', 'areaTotal']\n",
      "['birthPlace', 'birthDate']\n",
      "['numberOfLocations', 'location']\n",
      "['leaderTitle', 'residence']\n",
      "['deathPlace', 'birthPlace']\n",
      "['spouse', 'nationality']\n",
      "['birthDate', 'nationality']\n",
      "['genre', 'musicFusionGenre']\n",
      "['birthPlace', 'deathDate']\n",
      "['artist', 'runtime']\n",
      "['staff', 'numberOfDoctoralStudents']\n",
      "['genre', 'stylisticOrigin']\n",
      "['leaderTitle', 'birthPlace']\n",
      "['operatingOrganisation', 'foundedBy']\n",
      "['populationDensity', 'elevationAboveTheSeaLevel']\n",
      "['artist', 'producer']\n",
      "['youthclub', 'club']\n",
      "['deathPlace', 'leader']\n",
      "['birthPlace', 'leaderTitle']\n",
      "['starring', 'starring']\n",
      "['starring', 'birthPlace']\n",
      "['genre', 'musicFusionGenre']\n",
      "['birthPlace', 'professionalField']\n",
      "['industry', 'location']\n",
      "['musicComposer', 'club']\n",
      "['location', 'hasToItsSouthwest']\n",
      "['broadcastedBy', 'formerName']\n",
      "['discovered', 'periapsis']\n",
      "['cityServed', 'icaoLocationIdentifier']\n",
      "['status', 'mission']\n",
      "['mission', 'cosparId']\n",
      "['starring', 'runtime']\n",
      "['starring', 'writer']\n",
      "['birthPlace', 'areaTotal']\n",
      "['campus', 'country']\n",
      "['populationDensity', 'leader']\n",
      "['city', 'established']\n",
      "['operatingOrganisation', 'transportAircraft']\n",
      "['literaryGenre', 'author']\n",
      "['isPartOf', 'leaderTitle']\n",
      "['birthPlace', 'isPartOf']\n",
      "['residence', 'areaTotal']\n",
      "['knownFor', 'almaMater']\n",
      "['populationDensity', 'country']\n",
      "['producer', 'runtime']\n",
      "['director', 'broadcastedBy']\n",
      "['influencedBy', 'birthDate']\n",
      "['genre', 'genre']\n",
      "['training', 'birthDate']\n",
      "['citizenship', 'leader']\n",
      "['deathPlace', 'officialLanguage']\n",
      "['producer', 'runtime']\n",
      "['genre', 'associatedBand/associatedMusicalArtist']\n",
      "['residence', 'birthPlace']\n",
      "['residence', 'leader']\n",
      "['writer', 'writer']\n",
      "['assembly', 'language']\n",
      "['birthPlace', 'governmentType']\n",
      "['runwayName', 'operatingOrganisation']\n",
      "['region', 'country']\n",
      "['hasToItsWest', 'location']\n",
      "['birthDate', 'deathDate']\n",
      "['nationality', 'birthDate']\n",
      "['birthDate', 'almaMater']\n",
      "['director', 'editor']\n",
      "['almaMater', 'residence']\n",
      "['operatingOrganisation', 'icaoLocationIdentifier']\n",
      "['height', 'weight']\n",
      "['imdbId', 'director']\n",
      "['deathPlace', 'populationDensity']\n",
      "['leaderTitle', 'country']\n",
      "['height', 'birthPlace']\n",
      "['producer', 'genre']\n",
      "['totalProduction', 'length']\n",
      "['residence', 'leader']\n",
      "['mission', 'nationality']\n",
      "['runtime', 'director']\n",
      "['precededBy', 'followedBy']\n",
      "['genre', 'associatedBand/associatedMusicalArtist']\n",
      "['birthPlace', 'nationality']\n",
      "['country', 'course']\n",
      "['weight', 'birthPlace']\n",
      "['birthPlace', 'mission']\n",
      "['productionStartYear', 'bodyStyle']\n",
      "['dishVariation', 'country']\n",
      "['campus', 'city']\n",
      "['releaseDate', 'followedBy']\n",
      "['cylinderCount', 'builder']\n",
      "['precededBy', 'recordedIn']\n",
      "['professionalField', 'knownFor']\n",
      "['artist', 'genre']\n",
      "['genre', 'musicSubgenre']\n",
      "['birthPlace', 'knownFor']\n",
      "['operatingOrganisation', 'runwayName']\n",
      "['weight', 'birthDate']\n",
      "['league', 'numberOfMembers']\n",
      "['location', 'icaoLocationIdentifier']\n",
      "['spouse', 'office']\n",
      "['nationality', 'occupation']\n",
      "['birthDate', 'knownFor']\n",
      "['starring', 'birthPlace']\n",
      "['product', 'location']\n",
      "['deathPlace', 'country']\n",
      "['director', 'writer']\n",
      "['lastAired', 'broadcastedBy']\n",
      "['birthPlace', 'populationTotal']\n",
      "['currentTenants', 'location']\n",
      "['genre', 'recordLabel']\n",
      "['associatedBand/associatedMusicalArtist', 'producer']\n",
      "['country', 'dishVariation']\n",
      "['director', 'starring']\n",
      "['imdbId', 'writer']\n",
      "['author', 'precededBy']\n",
      "['musicComposer', 'birthDate']\n",
      "['genre', 'musicSubgenre']\n",
      "['birthPlace', 'nationality']\n",
      "['numberOfStudents', 'campus']\n",
      "['director', 'runtime']\n",
      "['apoapsis', 'absoluteMagnitude']\n",
      "['birthDate', 'height']\n",
      "['associatedBand/associatedMusicalArtist', 'producer']\n",
      "['doctoralAdvisor', 'birthPlace']\n",
      "['assembly', 'bodyStyle']\n",
      "['genre', 'precededBy']\n",
      "['followedBy', 'producer']\n",
      "['apoapsis', 'discovered']\n",
      "['populationDensity', 'timeZone']\n",
      "['apoapsis', 'discoverer']\n",
      "['league', 'season']\n",
      "['precededBy', 'producer']\n",
      "['genre', 'genre']\n",
      "['product', 'keyPerson']\n",
      "['doctoralAdvisor', 'birthDate']\n",
      "['nationality', 'leader']\n",
      "['league', 'ground']\n",
      "['icaoLocationIdentifier', 'runwaySurfaceType']\n",
      "['producer', 'runtime']\n",
      "['currentTenants', 'location']\n",
      "['cylinderCount', 'length']\n",
      "['birthPlace', 'currency']\n",
      "['precededBy', 'releaseDate']\n",
      "['engine', 'length']\n",
      "['foundedBy', 'broadcastedBy']\n",
      "['musicComposer', 'director']\n",
      "['debutTeam', 'activeYearsStartYear']\n",
      "['assembly', 'areaTotal']\n",
      "['firstAired', 'starring']\n",
      "['distributor', 'series']\n",
      "['operatingOrganisation', 'location']\n",
      "['publisher', 'followedBy']\n",
      "['followedBy', 'author']\n",
      "['numberOfPages', 'author']\n",
      "['numberOfUndergraduateStudents', 'staff']\n",
      "['producer', 'followedBy']\n",
      "['populationDensity', 'leaderTitle']\n",
      "['birthPlace', 'nationality']\n",
      "['genre', 'instrument']\n",
      "['established', 'country']\n",
      "['director', 'producer']\n",
      "['buildDate', 'length']\n",
      "['writer', 'cinematography']\n",
      "['location', 'country']\n",
      "['birthPlace', 'capital']\n",
      "['absoluteMagnitude', 'discovered']\n",
      "['birthPlace', 'almaMater']\n",
      "['director', 'occupation']\n",
      "['region', 'country']\n",
      "['releaseDate', 'runtime']\n",
      "['runwayLength', 'location']\n",
      "['musicComposer', 'birthDate']\n",
      "['birthPlace', 'nationality']\n",
      "['deathPlace', 'foundingDate']\n",
      "['genre', 'recordLabel']\n",
      "['producer', 'associatedBand/associatedMusicalArtist']\n",
      "['location', 'industry']\n",
      "['knownFor', 'birthDate']\n",
      "['debutTeam', 'birthDate']\n",
      "['cityServed', 'elevationAboveTheSeaLevel']\n",
      "['affiliation', 'numberOfPostgraduateStudents']\n",
      "['birthPlace', 'nationality']\n",
      "['birthPlace', 'birthDate']\n",
      "['discoverer', 'birthDate']\n",
      "['foundingDate', 'product']\n",
      "['knownFor', 'birthName']\n",
      "['icaoLocationIdentifier', 'runwayName']\n",
      "['genre', 'instrument']\n",
      "['address', 'owner']\n",
      "['discoverer', 'absoluteMagnitude']\n",
      "['operatingOrganisation', 'runwayLength']\n",
      "['influencedBy', 'author']\n",
      "['almaMater', 'affiliation']\n",
      "['genre', 'followedBy']\n",
      "['birthDate', 'birthPlace']\n",
      "['operatingOrganisation', 'runwayLength']\n",
      "['author', 'releaseDate']\n",
      "['staff', 'numberOfStudents']\n",
      "['knownFor', 'knownFor']\n",
      "['writer', 'birthDate']\n",
      "['birthPlace', 'birthDate']\n",
      "['professionalField', 'professionalField']\n",
      "['currentTenants', 'owner']\n",
      "['director', 'occupation']\n",
      "['genre', 'followedBy']\n",
      "['precededBy', 'runtime']\n",
      "['recordLabel', 'recordLabel']\n",
      "['numberOfEmployees', 'revenue']\n",
      "['birthPlace', 'deathPlace']\n",
      "['currentTenants', 'completionDate']\n",
      "['director', 'starring']\n",
      "['artist', 'genre']\n",
      "['birthDate', 'deathDate']\n",
      "['genre', 'associatedBand/associatedMusicalArtist']\n",
      "['genre', 'stylisticOrigin']\n",
      "['writer', 'runtime']\n",
      "['creator', 'firstAired']\n",
      "['buildDate', 'builder']\n",
      "['discoverer', 'birthPlace']\n",
      "['city', 'country']\n",
      "['knownFor', 'doctoralAdvisor']\n",
      "['numberOfEmployees', 'foundingDate']\n",
      "['publisher', 'author']\n",
      "['author', 'precededBy']\n",
      "['completionDate', 'location']\n",
      "['birthDate', 'birthPlace']\n",
      "['staff', 'numberOfPostgraduateStudents']\n",
      "['campus', 'city']\n",
      "['language', 'author']\n",
      "['associatedBand/associatedMusicalArtist', 'activeYearsStartYear']\n",
      "['genre', 'stylisticOrigin']\n",
      "['residence', 'party']\n",
      "['city', 'state']\n",
      "['birthDate', 'almaMater']\n",
      "['residence', 'leaderTitle']\n",
      "['precededBy', 'followedBy']\n",
      "['birthPlace', 'award']\n",
      "['genre', 'precededBy']\n",
      "['birthPlace', 'almaMater']\n",
      "['foundationPlace', 'leaderTitle']\n",
      "['starring', 'birthYear']\n",
      "['location', 'country']\n",
      "['mission', 'birthDate']\n",
      "['director', 'birthPlace']\n",
      "['producer', 'birthDate']\n",
      "['associatedBand/associatedMusicalArtist', 'genre']\n",
      "['birthDate', 'deathPlace']\n",
      "['league', 'nickname']\n",
      "['deathPlace', 'almaMater']\n",
      "['country', 'leaderTitle']\n",
      "['musicComposer', 'birthPlace']\n",
      "['runwayLength', 'elevationAboveTheSeaLevel']\n",
      "['populationMetro', 'populationDensity']\n",
      "['birthPlace', 'areaTotal']\n",
      "['isPartOf', 'country']\n",
      "['genre', 'producer']\n",
      "['productionStartYear', 'productionEndYear']\n",
      "['starring', 'writer']\n",
      "['dedicatedTo', 'designer']\n",
      "['numberOfPostgraduateStudents', 'country']\n",
      "['nationality', 'mission']\n",
      "['cityServed', 'location']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['influencedBy', 'professionalField']\n",
      "['productionStartYear', 'assembly']\n",
      "['professionalField', 'knownFor']\n",
      "['city', 'country']\n",
      "['numberOfDoctoralStudents', 'campus']\n",
      "['citizenship', 'birthDate']\n",
      "['precededBy', 'runtime']\n",
      "['birthPlace', 'leaderTitle']\n",
      "['course', 'region']\n",
      "['artist', 'genre']\n",
      "['genre', 'recordLabel']\n",
      "['broadcastedBy', 'firstAired']\n",
      "['birthPlace', 'deathDate']\n",
      "['birthPlace', 'occupation']\n",
      "['runtime', 'precededBy']\n",
      "['genre', 'associatedBand/associatedMusicalArtist']\n",
      "['runwayLength', 'icaoLocationIdentifier']\n",
      "['runwayLength', 'operatingOrganisation']\n",
      "['recordLabel', 'writer']\n",
      "['capital', 'nationality']\n",
      "['location', 'leaderTitle']\n",
      "['associatedBand/associatedMusicalArtist', 'instrument']\n",
      "['location', 'state']\n",
      "['country', 'state']\n",
      "['publisher', 'releaseDate']\n",
      "['author', 'notableWork']\n",
      "['manufacturer', 'successor']\n",
      "['draftRound', 'debutTeam']\n",
      "['spouse', 'nationality']\n",
      "['runwayName', 'runwaySurfaceType']\n",
      "['nationality', 'language']\n",
      "['mission', 'almaMater']\n",
      "['birthPlace', 'birthPlace']\n",
      "['starring', 'occupation']\n",
      "['birthDate', 'nationality']\n",
      "['birthPlace', 'governmentType']\n",
      "['artist', 'producer']\n",
      "['leaderTitle', 'isPartOf']\n",
      "['league', 'nickname']\n",
      "['citizenship', 'leaderTitle']\n",
      "['numberOfUndergraduateStudents', 'numberOfDoctoralStudents']\n",
      "['literaryGenre', 'followedBy']\n",
      "['starring', 'birthYear']\n",
      "['runtime', 'director']\n",
      "['precededBy', 'recordLabel']\n",
      "['numberOfUndergraduateStudents', 'numberOfPostgraduateStudents']\n",
      "['utcOffset', 'country']\n",
      "['followedBy', 'releaseDate']\n",
      "['producer', 'birthPlace']\n",
      "['runwayLength', 'cityServed']\n",
      "['course', 'region']\n",
      "['influencedBy', 'knownFor']\n",
      "['regionServed', 'country']\n",
      "['league', 'season']\n",
      "['governmentType', 'nationality']\n",
      "['producer', 'writer']\n",
      "['populationDensity', 'isPartOf']\n",
      "['birthPlace', 'nationality']\n",
      "['citizenship', 'professionalField']\n",
      "['city', 'numberOfPostgraduateStudents']\n",
      "['genre', 'producer']\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def twoRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF2_predicate_train)):\n",
    "        if test_pred[0] in RDF2_predicate_train[i] and test_pred[1] in RDF2_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF2_train_data[i][0])\n",
    "            train_matching_text.append(RDF2_train_data[i][1])\n",
    "            \n",
    "                \n",
    "    for x in train_matching_index:           \n",
    "        if RDF2_subject_train[x][0] in str(RDF2_train_data[x][1]) and RDF2_object_train[x][0] in str(RDF2_train_data[x][1]) and RDF2_subject_train[x][1] in str(RDF2_train_data[x][1]) and RDF2_object_train[x][1] in str(RDF2_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF2_train_data[x][1]).replace(RDF2_subject_train[x][0], test_sub[0]).replace(RDF2_subject_train[x][1], test_sub[1]).replace(RDF2_object_train[x][0], test_obj[0]).replace(RDF2_object_train[x][1], test_obj[1])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "            \n",
    "    references = [RDF2_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original        \n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    if bleu_scores:\n",
    "        # returning the modified text with the biggest blue score\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    else:\n",
    "        # if no matches\n",
    "        # call oneRDF twice, once for each triple \n",
    "        original1, generated1 = oneRDF(test_sub[0],test_pred[0],test_obj[0])\n",
    "        original2, generated2 = oneRDF(test_sub[1],test_pred[1],test_obj[1])\n",
    "        if generated1 != None and generated2 != None:\n",
    "            # adding the texts togethor and return\n",
    "            o = original1+ \" \"+original2\n",
    "            g = generated1+\" \"+generated2\n",
    "            return o , g\n",
    "        else:\n",
    "            #if still no matches found\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 2/RDF2_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF2_predicate_test)):\n",
    "        print(str(RDF2_predicate_test[x]))\n",
    "        original, generated = twoRDF(RDF2_subject_test[x],RDF2_predicate_test[x],RDF2_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30861c52",
   "metadata": {},
   "source": [
    "### 3 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac598fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF 1.1.1\n",
      "RDF 1.1.1\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def threeRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF3_predicate_train)):\n",
    "        if test_pred[0] in RDF3_predicate_train[i] and test_pred[1] in RDF3_predicate_train[i] and test_pred[2] in RDF3_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF3_train_data[i][0])\n",
    "            train_matching_text.append(RDF3_train_data[i][1])\n",
    "                       \n",
    "    for x in train_matching_index: \n",
    "        if RDF3_subject_train[x][0] in str(RDF3_train_data[x][1]) and RDF3_object_train[x][0] in str(RDF3_train_data[x][1]) and RDF3_subject_train[x][1] in str(RDF3_train_data[x][1]) and RDF3_object_train[x][1] in str(RDF3_train_data[x][1]) and RDF3_subject_train[x][2] in str(RDF3_train_data[x][1]) and RDF3_object_train[x][2] in str(RDF3_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF3_train_data[x][1]).replace(RDF3_subject_train[x][0], test_sub[0]).replace(RDF3_subject_train[x][1], test_sub[1]).replace(RDF3_subject_train[x][2], test_sub[2]).replace(RDF3_object_train[x][0], test_obj[0]).replace(RDF3_object_train[x][1], test_obj[1]).replace(RDF3_object_train[x][2], test_obj[2])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "    references = [RDF3_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        print('RDF3')\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    else:\n",
    "        # if no matches\n",
    "        # call oneRDF, 3 times for each triple\n",
    "        original1, generated1 = oneRDF(test_sub[0],test_pred[0],test_obj[0])\n",
    "        original2, generated2 = oneRDF(test_sub[1],test_pred[1],test_obj[1])\n",
    "        original3, generated3 = oneRDF(test_sub[2],test_pred[2],test_obj[2])\n",
    "        \n",
    "        bleu_score1 = 0\n",
    "        if generated1 != None and generated2 != None and generated3 != None:\n",
    "            # add the texts togethor and find blue score\n",
    "            o = original1+ \" \"+original2+ \" \"+ original3\n",
    "            g = generated1+\" \"+generated2+\" \"+generated3\n",
    "            bleu_score1 = sentence_bleu([o], g)\n",
    "        \n",
    "        # call twoRDF and oneRDF\n",
    "        original1, generated1 = twoRDF([test_sub[0],test_sub[1]],[test_pred[0],test_pred[1]],[test_obj[0],test_obj[1]])\n",
    "        original2, generated2 = oneRDF(test_sub[2],test_pred[2],test_obj[2]) \n",
    "        \n",
    "        bleu_score2 = 0\n",
    "        o2 =''\n",
    "        g2 = ''\n",
    "        if generated1 != None and generated2 != None :\n",
    "            # add the texts togethor and find the blue score\n",
    "            o2 = original1+ \" \"+original2\n",
    "            g2 = generated1+\" \"+generated2\n",
    "            bleu_score2 = sentence_bleu([o2], g2)\n",
    "         \n",
    "        # return the text with the biggest blue score\n",
    "        if bleu_score2 > bleu_score1:\n",
    "            print('RDF2.1')\n",
    "            return(o2, g2)\n",
    "        \n",
    "        elif bleu_score2 < bleu_score1:\n",
    "            print('RDF 1.1.1')\n",
    "            return(o,g)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 3/RDF3_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF3_predicate_test)):\n",
    "        original, generated = threeRDF(RDF3_subject_test[x],RDF3_predicate_test[x],RDF3_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81102d79",
   "metadata": {},
   "source": [
    "### 4 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6989790d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def fourRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF4_predicate_train)):\n",
    "        if test_pred[0] in RDF4_predicate_train[i] and test_pred[1] in RDF4_predicate_train[i] and test_pred[2] in RDF4_predicate_train[i] and test_pred[3] in RDF4_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF4_train_data[i][0])\n",
    "            train_matching_text.append(RDF4_train_data[i][1])\n",
    "                       \n",
    "    for x in train_matching_index: \n",
    "        if RDF4_subject_train[x][0] in str(RDF4_train_data[x][1]) and RDF4_object_train[x][0] in str(RDF4_train_data[x][1]) and RDF4_subject_train[x][1] in str(RDF4_train_data[x][1]) and RDF4_object_train[x][1] in str(RDF4_train_data[x][1]) and RDF4_subject_train[x][2] in str(RDF4_train_data[x][1]) and RDF4_object_train[x][2] in str(RDF4_train_data[x][1])and RDF4_subject_train[x][3] in str(RDF4_train_data[x][1]) and RDF4_object_train[x][3] in str(RDF4_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF4_train_data[x][1]).replace(RDF4_subject_train[x][0], test_sub[0]).replace(RDF4_subject_train[x][1], test_sub[1]).replace(RDF4_subject_train[x][2], test_sub[2]).replace(RDF4_subject_train[x][3], test_sub[3]).replace(RDF4_object_train[x][0], test_obj[0]).replace(RDF4_object_train[x][1], test_obj[1]).replace(RDF4_object_train[x][2], test_obj[2]).replace(RDF4_object_train[x][3], test_obj[3])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "    references = [RDF4_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        print('RDF4')\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    else:\n",
    "        #if no match\n",
    "        # call threeRDF and oneRDF\n",
    "        original1, generated1 = threeRDF([test_sub[0],test_sub[1],test_sub[2]],[test_pred[0],test_pred[1],test_pred[2]],[test_obj[0],test_obj[1],test_obj[2]])\n",
    "        original2, generated2 = oneRDF(test_sub[3],test_pred[3],test_obj[3])\n",
    "        \n",
    "        \n",
    "        bleu_score1 = 0\n",
    "        if generated1 != None and generated2 != None :\n",
    "            # add text togethor and find blue score\n",
    "            o = original1+ \" \"+original2\n",
    "            g = generated1+\" \"+generated2\n",
    "            bleu_score1 = sentence_bleu([o], g)\n",
    "        \n",
    "        #call twoRDF twice   \n",
    "        original1, generated1 = twoRDF([test_sub[0],test_sub[1]],[test_pred[0],test_pred[1]],[test_obj[0],test_obj[1]])\n",
    "        original2, generated2 = twoRDF([test_sub[2],test_sub[3]],[test_pred[2],test_pred[3]],[test_obj[2],test_obj[3]]) \n",
    "        \n",
    "        bleu_score2 = 0\n",
    "        o2 =''\n",
    "        g2 = ''\n",
    "        if generated1 != None and generated2 != None :\n",
    "            # add the texts togethor and find the blue score \n",
    "            o2 = original1+ \" \"+original2\n",
    "            g2 = generated1+\" \"+generated2\n",
    "            bleu_score2 = sentence_bleu([o2], g2)\n",
    "        \n",
    "        # return the text with the biggest blue score\n",
    "        if bleu_score2 < bleu_score1:\n",
    "            print('RDF 3.1')\n",
    "            return(o,g)\n",
    "            \n",
    "        \n",
    "        elif bleu_score2 > bleu_score1:\n",
    "            print('RDF2.2')\n",
    "            return(o2, g2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 4/RDF4_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF4_predicate_test)):\n",
    "        original, generated = fourRDF(RDF4_subject_test[x],RDF4_predicate_test[x],RDF4_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b6d9e",
   "metadata": {},
   "source": [
    "### 5 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff1f0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF3\n",
      "RDF3.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF3\n",
      "RDF3.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF 3.1\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 1.1.1\n",
      "RDF 3.1\n",
      "RDF 1.1.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF 1.1.1\n",
      "RDF3.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def fiveRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF5_predicate_train)):\n",
    "        if test_pred[0] in RDF5_predicate_train[i] and test_pred[1] in RDF5_predicate_train[i] and test_pred[2] in RDF5_predicate_train[i] and test_pred[3] in RDF5_predicate_train[i] and test_pred[4] in RDF5_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF5_train_data[i][0])\n",
    "            train_matching_text.append(RDF5_train_data[i][1])\n",
    "                       \n",
    "    for x in train_matching_index: \n",
    "        if RDF5_subject_train[x][0] in str(RDF5_train_data[x][1]) and RDF5_object_train[x][0] in str(RDF5_train_data[x][1]) and RDF5_subject_train[x][1] in str(RDF5_train_data[x][1]) and RDF5_object_train[x][1] in str(RDF5_train_data[x][1]) and RDF5_subject_train[x][2] in str(RDF5_train_data[x][1]) and RDF5_object_train[x][2] in str(RDF5_train_data[x][1])and RDF5_subject_train[x][3] in str(RDF5_train_data[x][1]) and RDF5_object_train[x][3] in str(RDF5_train_data[x][1])and RDF5_subject_train[x][4] in str(RDF5_train_data[x][1]) and RDF5_object_train[x][4] in str(RDF5_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF5_train_data[x][1]).replace(RDF5_subject_train[x][0], test_sub[0]).replace(RDF5_subject_train[x][1], test_sub[1]).replace(RDF5_subject_train[x][2], test_sub[2]).replace(RDF5_subject_train[x][3], test_sub[3]).replace(RDF5_subject_train[x][4], test_sub[4]).replace(RDF5_object_train[x][0], test_obj[0]).replace(RDF5_object_train[x][1], test_obj[1]).replace(RDF5_object_train[x][2], test_obj[2]).replace(RDF5_object_train[x][3], test_obj[3]).replace(RDF5_object_train[x][4], test_obj[4])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "    references = [RDF5_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    \n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        print('RDF5')\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # call fourRDF and oneRDF\n",
    "        original1, generated1 = fourRDF([test_sub[0],test_sub[1],test_sub[2],test_sub[3]],[test_pred[0],test_pred[1],test_pred[2],test_pred[3]],[test_obj[0],test_obj[1],test_obj[2],test_obj[3]])\n",
    "        original2, generated2 = oneRDF(test_sub[4],test_pred[4],test_obj[4]) \n",
    "        \n",
    "        bleu_score1 = 0\n",
    "        if generated1 != None and generated2 != None :\n",
    "            #add the texts togethor and find the blue score\n",
    "            o = original1+ \" \"+original2\n",
    "            g = generated1+\" \"+generated2\n",
    "            bleu_score1 = sentence_bleu([o], g)\n",
    "         \n",
    "        # call threeRDF and twoRDF\n",
    "        original1, generated1 = threeRDF([test_sub[0],test_sub[1],test_sub[2]],[test_pred[0],test_pred[1],test_pred[2]],[test_obj[0],test_obj[1],test_obj[2]])\n",
    "        original2, generated2 = twoRDF([test_sub[3],test_sub[4]],[test_pred[3],test_pred[4]],[test_obj[3],test_obj[4]]) \n",
    "        \n",
    "        bleu_score2 = 0\n",
    "        o2 =''\n",
    "        g2 = ''\n",
    "        if generated1 != None and generated2 != None :\n",
    "            #add the texts togethor and find the blue score\n",
    "            o2 = original1+ \" \"+original2\n",
    "            g2 = generated1+\" \"+generated2\n",
    "            bleu_score2 = sentence_bleu([o2], g2)\n",
    "        \n",
    "        # return the text with the biggest blue score\n",
    "        if bleu_score2 < bleu_score1:\n",
    "            print('RDF 4.1')\n",
    "            return(o,g)\n",
    "            \n",
    "        \n",
    "        elif bleu_score2 > bleu_score1:\n",
    "            print('RDF3.2')\n",
    "            return(o2, g2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 5/RDF5_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF5_predicate_test)):\n",
    "        original, generated = fiveRDF(RDF5_subject_test[x],RDF5_predicate_test[x],RDF5_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf9499",
   "metadata": {},
   "source": [
    "### 6 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88dbabac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF3\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF3.2\n",
      "RDF4\n",
      "RDF4.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF3.2\n",
      "RDF4\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF4\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF4\n",
      "RDF3\n",
      "RDF3.2\n",
      "RDF4\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF3.2\n",
      "RDF2.1\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF4\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF3\n",
      "RDF 4.1\n",
      "RDF3\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def sixRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF6_predicate_train)):\n",
    "        if test_pred[0] in RDF6_predicate_train[i] and test_pred[1] in RDF6_predicate_train[i] and test_pred[2] in RDF6_predicate_train[i] and test_pred[3] in RDF6_predicate_train[i] and test_pred[4] in RDF6_predicate_train[i] and test_pred[5] in RDF6_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF6_train_data[i][0])\n",
    "            train_matching_text.append(RDF6_train_data[i][1])\n",
    "                       \n",
    "    for x in train_matching_index: \n",
    "        if RDF6_subject_train[x][0] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][0] in str(RDF6_train_data[x][1]) and RDF6_subject_train[x][1] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][1] in str(RDF6_train_data[x][1]) and RDF6_subject_train[x][2] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][2] in str(RDF6_train_data[x][1])and RDF6_subject_train[x][3] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][3] in str(RDF6_train_data[x][1])and RDF6_subject_train[x][4] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][4] in str(RDF6_train_data[x][1]) and RDF6_subject_train[x][5] in str(RDF6_train_data[x][1]) and RDF6_object_train[x][5] in str(RDF6_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF6_train_data[x][1]).replace(RDF6_subject_train[x][0], test_sub[0]).replace(RDF6_subject_train[x][1], test_sub[1]).replace(RDF6_subject_train[x][2], test_sub[2]).replace(RDF6_subject_train[x][3], test_sub[3]).replace(RDF6_subject_train[x][4], test_sub[4]).replace(RDF6_subject_train[x][5], test_sub[5]).replace(RDF6_object_train[x][0], test_obj[0]).replace(RDF6_object_train[x][1], test_obj[1]).replace(RDF6_object_train[x][2], test_obj[2]).replace(RDF6_object_train[x][3], test_obj[3]).replace(RDF6_object_train[x][4], test_obj[4]).replace(RDF6_object_train[x][5], test_obj[5])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "    references = [RDF6_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    \n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        print('RDF6')\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        #call fiveRDF and oneRDF\n",
    "        original1, generated1 = fiveRDF([test_sub[0],test_sub[1],test_sub[2],test_sub[3],test_sub[4]],[test_pred[0],test_pred[1],test_pred[2],test_pred[3],test_pred[4]],[test_obj[0],test_obj[1],test_obj[2],test_obj[3],test_obj[4]])\n",
    "        original2, generated2 = oneRDF(test_sub[5],test_pred[5],test_obj[5]) \n",
    "        \n",
    "        bleu_score1 = 0\n",
    "        if generated1 != None and generated2 != None :\n",
    "            #add the texts togethor and find the blue score\n",
    "            o = original1+ \" \"+original2\n",
    "            g = generated1+\" \"+generated2\n",
    "            bleu_score1 = sentence_bleu([o], g)\n",
    "         \n",
    "        #call fourRDF and twoRDF\n",
    "        original1, generated1 = fourRDF([test_sub[0],test_sub[1],test_sub[2],test_sub[3]],[test_pred[0],test_pred[1],test_pred[2],test_pred[3]],[test_obj[0],test_obj[1],test_obj[2],test_obj[3]])\n",
    "        original2, generated2 = twoRDF([test_sub[4],test_sub[5]],[test_pred[4],test_pred[5]],[test_obj[4],test_obj[5]]) \n",
    "        \n",
    "        bleu_score2 = 0\n",
    "        o2 =''\n",
    "        g2 = ''\n",
    "        if generated1 != None and generated2 != None :\n",
    "            #add the texts togethor and find the blue score\n",
    "            o2 = original1+ \" \"+original2\n",
    "            g2 = generated1+\" \"+generated2\n",
    "            bleu_score2 = sentence_bleu([o2], g2)\n",
    "        \n",
    "        #return the texts with the biggest blue score\n",
    "        if bleu_score2 < bleu_score1:\n",
    "            print('RDF 5.1')\n",
    "            return(o,g)\n",
    "            \n",
    "        \n",
    "        elif bleu_score2 > bleu_score1:\n",
    "            print('RDF4.2')\n",
    "            return(o2, g2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 6/RDF6_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF6_predicate_test)):\n",
    "        original, generated = sixRDF(RDF6_subject_test[x],RDF6_predicate_test[x],RDF6_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a476942",
   "metadata": {},
   "source": [
    "### 7 Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e19eb2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF4.2\n",
      "RDF2.1\n",
      "RDF 3.1\n",
      "RDF2.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF4.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF 6.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 5.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF2.2\n",
      "RDF2.2\n",
      "RDF 4.1\n",
      "RDF5.2\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF4\n",
      "RDF4\n",
      "RDF2.1\n",
      "RDF 4.1\n",
      "RDF5.2\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def sevenRDF(test_sub, test_pred, test_obj):\n",
    "    train_matching_triple = []\n",
    "    train_matching_text = []\n",
    "    train_matching_index = []\n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i in range(len(RDF7_predicate_train)):\n",
    "        if test_pred[0] in RDF7_predicate_train[i] and test_pred[1] in RDF7_predicate_train[i] and test_pred[2] in RDF7_predicate_train[i] and test_pred[3] in RDF7_predicate_train[i] and test_pred[4] in RDF7_predicate_train[i] and test_pred[5] in RDF7_predicate_train[i] and test_pred[6] in RDF7_predicate_train[i]:\n",
    "            # Finding Matching Triples with their predicated\n",
    "            train_matching_index.append(i)\n",
    "            train_matching_triple.append(RDF7_train_data[i][0])\n",
    "            train_matching_text.append(RDF7_train_data[i][1])\n",
    "                       \n",
    "    for x in train_matching_index: \n",
    "        if RDF7_subject_train[x][0] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][0] in str(RDF7_train_data[x][1]) and RDF7_subject_train[x][1] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][1] in str(RDF7_train_data[x][1]) and RDF7_subject_train[x][2] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][2] in str(RDF7_train_data[x][1])and RDF7_subject_train[x][3] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][3] in str(RDF7_train_data[x][1])and RDF7_subject_train[x][4] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][4] in str(RDF7_train_data[x][1]) and RDF7_subject_train[x][5] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][5] in str(RDF7_train_data[x][1])and RDF7_subject_train[x][6] in str(RDF7_train_data[x][1]) and RDF7_object_train[x][6] in str(RDF7_train_data[x][1]):\n",
    "            # Modifing info\n",
    "            modified_sentence = str(RDF7_train_data[x][1]).replace(RDF7_subject_train[x][0], test_sub[0]).replace(RDF7_subject_train[x][1], test_sub[1]).replace(RDF7_subject_train[x][2], test_sub[2]).replace(RDF7_subject_train[x][3], test_sub[3]).replace(RDF7_subject_train[x][4], test_sub[4]).replace(RDF7_subject_train[x][5], test_sub[5]).replace(RDF7_subject_train[x][6], test_sub[6]).replace(RDF7_object_train[x][0], test_obj[0]).replace(RDF7_object_train[x][1], test_obj[1]).replace(RDF7_object_train[x][2], test_obj[2]).replace(RDF7_object_train[x][3], test_obj[3]).replace(RDF7_object_train[x][4], test_obj[4]).replace(RDF7_object_train[x][5], test_obj[5]).replace(RDF7_object_train[x][6], test_obj[6])\n",
    "            modified_sentences.append(modified_sentence.strip())\n",
    "            \n",
    "    references = [RDF7_train_data[i][1] for i in train_matching_index]\n",
    "    bleu_scores = []\n",
    "    for reference, generated_sentence in zip(references, modified_sentences):\n",
    "        # finding Blue score of each Modified against the original\n",
    "        bleu_score = sentence_bleu([reference], generated_sentence)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    \n",
    "    if bleu_scores:\n",
    "        #returning the modified text with the biggest blue score\n",
    "        print('RDF7')\n",
    "        best_generated_index = bleu_scores.index(max(bleu_scores))\n",
    "        best_generated_sentence = modified_sentences[best_generated_index]\n",
    "        best_original_sentence = references[best_generated_index]\n",
    "        return best_original_sentence, best_generated_sentence\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        #call sixRDF and oneRDF\n",
    "        original1, generated1 = sixRDF([test_sub[0],test_sub[1],test_sub[2],test_sub[3],test_sub[4],test_sub[5]],[test_pred[0],test_pred[1],test_pred[2],test_pred[3],test_pred[4],test_pred[5]],[test_obj[0],test_obj[1],test_obj[2],test_obj[3],test_obj[4],test_obj[5]])\n",
    "        original2, generated2 = oneRDF(test_sub[6],test_pred[6],test_obj[6]) \n",
    "        \n",
    "        bleu_score1 = 0\n",
    "        if generated1 != None and generated2 != None :\n",
    "            # add the texts togethor and find the blue score \n",
    "            o = original1+ \" \"+original2\n",
    "            g = generated1+\" \"+generated2\n",
    "            bleu_score1 = sentence_bleu([o], g)\n",
    "        \n",
    "        # call fiveRDF and twoRDF\n",
    "        original1, generated1 = fiveRDF([test_sub[0],test_sub[1],test_sub[2],test_sub[3],test_sub[4]],[test_pred[0],test_pred[1],test_pred[2],test_pred[3],test_pred[4]],[test_obj[0],test_obj[1],test_obj[2],test_obj[3],test_obj[4]])\n",
    "        original2, generated2 = twoRDF([test_sub[5],test_sub[6]],[test_pred[5],test_pred[6]],[test_obj[5],test_obj[6]]) \n",
    "        \n",
    "        bleu_score2 = 0\n",
    "        o2 =''\n",
    "        g2 = ''\n",
    "        if generated1 != None and generated2 != None :\n",
    "            #add texts togethor and find the blue score\n",
    "            o2 = original1+ \" \"+original2\n",
    "            g2 = generated1+\" \"+generated2\n",
    "            bleu_score2 = sentence_bleu([o2], g2)\n",
    "        \n",
    "        #return the text with the biggest blue score\n",
    "        if bleu_score2 < bleu_score1:\n",
    "            print('RDF 6.1')\n",
    "            return(o,g)\n",
    "            \n",
    "        \n",
    "        elif bleu_score2 > bleu_score1:\n",
    "            print('RDF5.2')\n",
    "            return(o2, g2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    \n",
    "with open('RDF 7/RDF7_Generated.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for x in range(len(RDF7_predicate_test)):\n",
    "        original, generated = sevenRDF(RDF7_subject_test[x],RDF7_predicate_test[x],RDF7_object_test[x])\n",
    "        if original != None and generated != None:\n",
    "            f.write(\"Train text: \"+  original+ \"\\n\")\n",
    "            f.write(\"Generated text: \" +generated+ \"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d4ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
